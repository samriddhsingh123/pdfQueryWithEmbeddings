package com.pdfQuery.example.pdfQuery.service;

import org.springframework.stereotype.Service;
import org.springframework.beans.factory.annotation.Value;
import org.springframework.ai.chat.ChatResponse;
import org.springframework.ai.chat.prompt.Prompt;
import org.springframework.ai.ollama.OllamaChatClient;
import reactor.core.publisher.Mono;
import org.spring.ai.ollama.chat.options.*;

@Service
public class PdfQnAService {

    private final OllamaChatClient ollamaChatClient;

    @Value("${ollama.model:llama3.1}")
    private String ollamaModel;

    public PdfQnAService(OllamaChatClient ollamaChatClient) {
        this.ollamaChatClient = ollamaChatClient;
    }

    public Mono<String> askQuestion(String pdfContent, String question) {
        String fullPrompt = "PDF Content:\n" + pdfContent + "\n\nQuestion: " + question;
        Prompt prompt = Prompt.of(fullPrompt, ollamaModel);
        ChatResponse response = chatModel.call(
        	    new Prompt(
        	        "Generate the names of 5 famous pirates.",
        	        OllamaOptions.builder()
        	            .withModel(OllamaModel.LLAMA3_1)
        	            .withTemperature(0.4)
        	            .build()
        	    ));
        return ollamaChatClient
                .chat(prompt)
                .map(ChatResponse::getText)
                .onErrorReturn("Unable to process the question with the llama3.1 model. Please check the setup or try again.");
    }
}
